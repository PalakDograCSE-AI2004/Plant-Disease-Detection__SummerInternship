{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PalakDograCSE-AI2004/Plant-Disease-Detection__SummerInternship/blob/main/PROJECT_PDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL4vjQ06uT2Z"
      },
      "outputs": [],
      "source": [
        "# project plant disease detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhGlu_GWu3XW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from sklearn import svm, neighbors, ensemble, tree, naive_bayes\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "#import timm\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6AVIQKIq3Ns",
        "outputId": "00fec3d3-b31b-4c16-8e6e-7f96463674b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6M1vAxGvUkM"
      },
      "outputs": [],
      "source": [
        "zip_file_path =\"drive/MyDrive/archive.zip\"\n",
        "extract_path =\"drive/MyDrive/plantdiseasedetection\"\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGixMr-BwxXL"
      },
      "outputs": [],
      "source": [
        "# 1. Data Augmentation\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((224, 224)),  # Resize images to a consistent size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkxNq0xUnywR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00965098-4f17-4680-deab-8d85f341d16a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65tMqsYOxaG4"
      },
      "outputs": [],
      "source": [
        "# 2. Load and Preprocess Data\n",
        "\n",
        "data_path = \"drive/MyDrive/plantdiseasedetection\"\n",
        "dataset = ImageFolder(data_path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geJEfNbJybow"
      },
      "outputs": [],
      "source": [
        "# 3. Splitting the Data\n",
        "\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32)\n",
        "test_loader = DataLoader(test_set, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab8A7MwqyfmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aabbf0a7-cf1b-43a2-bfda-65b04bb4fb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 94.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 4. Feature Extraction (Using CNN Features)\n",
        "model = models.resnet18(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the last FC layer\n",
        "\n",
        "def extract_features(loader):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            outputs = model(inputs)  # Use tensor inputs directly\n",
        "            features.extend(outputs)\n",
        "            labels.extend(targets)\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(train_loader)\n",
        "val_features, val_labels = extract_features(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99bDKHtz3bAX"
      },
      "outputs": [],
      "source": [
        "train_features_numpy = torch.stack(train_features).numpy()\n",
        "val_features_numpy = torch.stack(val_features).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up9YcIm23ldr"
      },
      "outputs": [],
      "source": [
        "train_features_flattened = train_features_numpy.reshape(len(train_features_numpy), -1)\n",
        "val_features_flattened = val_features_numpy.reshape(len(val_features_numpy), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbno5YKD-ZUO"
      },
      "outputs": [],
      "source": [
        "train_labels_numpy = np.array(train_labels)\n",
        "val_labels_numpy = np.array(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYEuB-a8-dc9"
      },
      "outputs": [],
      "source": [
        "# Defining the parameters grid for GridSearchCV\n",
        "param_grid={'C':[0.1,1,10,100],\n",
        "            'gamma':[0.0001,0.001,0.1,1],\n",
        "            'kernel':['rbf','poly']}\n",
        "\n",
        "# Creating a support vector classifier\n",
        "svc=svm.SVC(probability=True)\n",
        "\n",
        "# Creating a model using GridSearchCV with the parameters grid\n",
        "model=GridSearchCV(svc,param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qak_oXMy-hVB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "49261ced-f9dd-4194-aabc-3019602e70ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(probability=True),\n",
              "             param_grid={'C': [0.1, 1, 10, 100],\n",
              "                         'gamma': [0.0001, 0.001, 0.1, 1],\n",
              "                         'kernel': ['rbf', 'poly']})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(probability=True),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
              "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.1, 1],\n",
              "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(probability=True),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
              "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.1, 1],\n",
              "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Training the model using the training data\n",
        "model.fit(train_features_flattened, train_labels_numpy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzDrMMuP-kxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7edfe6fd-8210-476b-a2ba-63c1fdc9ecf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model is 99.73821989528795% accurate\n"
          ]
        }
      ],
      "source": [
        "# Testing the model using the testing data\n",
        "y_pred = model.predict(val_features_flattened)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "accuracy = accuracy_score(val_labels_numpy, y_pred)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print(f\"The model is {accuracy*100}% accurate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlKkOcU7YMSC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPrhh3W5bBAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15dac2a3-bf9a-4cf4-ca23-e3402bea7766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The KNN model is 97.90575916230367% accurate\n"
          ]
        }
      ],
      "source": [
        "# Create a KNN classifier\n",
        "knn = KNeighborsClassifier()  # You can adjust the number of neighbors (k)\n",
        "\n",
        "# Train the KNN model on the training data\n",
        "knn.fit(train_features_flattened, train_labels_numpy)\n",
        "\n",
        "# Testing the KNN model using the validation data\n",
        "y_pred_knn = knn.predict(val_features_flattened)\n",
        "\n",
        "# Calculating the accuracy of the KNN model\n",
        "accuracy_knn = accuracy_score(val_labels_numpy, y_pred_knn)\n",
        "\n",
        "# Print the accuracy of the KNN model\n",
        "print(f\"The KNN model is {accuracy_knn*100}% accurate\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYmftb5wY6x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ea32fe-76f3-40fe-ec15-75cc743cf864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Random Forest is 98.95287958115183% accurate\n"
          ]
        }
      ],
      "source": [
        "rf_model = ensemble.RandomForestClassifier()\n",
        "rf_model.fit(train_features_flattened, train_labels_numpy)\n",
        "rf_predictions = rf_model.predict(val_features_flattened)\n",
        "rf_accuracy = accuracy_score(val_labels_numpy, rf_predictions)\n",
        "print(f\"The Random Forest is {rf_accuracy*100}% accurate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLRmNX6M-pEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7a6133-5f3d-4a92-dca0-ff64a1e18669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Decision Tree is 98.29842931937172% accurate\n"
          ]
        }
      ],
      "source": [
        "dt_model = tree.DecisionTreeClassifier()\n",
        "dt_model.fit(train_features_flattened, train_labels_numpy)\n",
        "dt_predictions = dt_model.predict(val_features_flattened)\n",
        "dt_accuracy = accuracy_score(val_labels_numpy, dt_predictions)\n",
        "print(f\"The Decision Tree is {dt_accuracy*100}% accurate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFcTcWKNWNNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0120f08a-7420-48fd-a92d-2e18822d2764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Naive Bayes is 95.02617801047121% accurate\n"
          ]
        }
      ],
      "source": [
        "nb_model = naive_bayes.GaussianNB()\n",
        "nb_model.fit(train_features_flattened, train_labels_numpy)\n",
        "nb_predictions = nb_model.predict(val_features_flattened)\n",
        "nb_accuracy = accuracy_score(val_labels_numpy, nb_predictions)\n",
        "print(f\"The Naive Bayes is {nb_accuracy*100}% accurate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgEYiU2efL6Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uBPAz5sI34f"
      },
      "source": [
        "'''class ImageClassificationBase(nn.Module):\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUuK4CFaMoyx"
      },
      "outputs": [],
      "source": [
        "#CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD_KaRiGMo_l"
      },
      "outputs": [],
      "source": [
        "# Create a custom dataset class\n",
        "class PlantDiseaseDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load data from subdirectories\n",
        "        for label in os.listdir(data_dir):\n",
        "            label_dir = os.path.join(data_dir, label)\n",
        "            for image_file in os.listdir(label_dir):\n",
        "                self.images.append(os.path.join(label_dir, image_file))\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def _len_(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def _getitem_(self, idx):\n",
        "        image = Image.open(self.images[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Create dataset and dataloaders\n",
        "dataset = PlantDiseaseDataset(data_dir=data_path, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oab8q_JLM0jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617b9fe9-e951-4e07-e17b-0965bae87bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=True)  # You can use other pre-trained models as well\n",
        "num_classes = 30  # Number of disease classes\n",
        "\n",
        "# Modify the final fully connected layer to match the number of classes\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE6zjtgtM4TJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1137fcb-32d0-45c3-e726-e22bde5fead8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.09052714748395374\n",
            "Epoch 2/10, Loss: 0.02388353709875446\n",
            "Epoch 3/10, Loss: 0.00569027583622171\n",
            "Epoch 4/10, Loss: 0.008434237002721343\n",
            "Epoch 5/10, Loss: 0.009352539188122526\n",
            "Epoch 6/10, Loss: 0.001573430643393944\n",
            "Epoch 7/10, Loss: 0.002946820953671444\n",
            "Epoch 8/10, Loss: 0.032009144067144134\n",
            "Epoch 9/10, Loss: 0.01013190427823117\n",
            "Epoch 10/10, Loss: 0.004241926611476694\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"plant_disease_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdJ1c0D4M8uT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd5418c-db24-4794-8753-b4f2a121c17f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 100.0%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Validation Accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkG42pXUoRfL",
        "outputId": "d07b073c-6edb-492d-cd01-b1b6869d6cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n4Q6FKI0-xR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0bbb1bc-b222-4b05-def2-02af8c1e4ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Metrics:\n",
            "SVM: Accuracy=0.9973821989528796, Precision=0.9974554707379135, Recall=0.9974554707379135, F1-score=0.9974554707379135\n",
            "KNN: Accuracy=0.9790575916230366, Precision=0.960880195599022, Recall=1.0, F1-score=0.9800498753117207\n",
            "Random Forest: Accuracy=0.9895287958115183, Precision=0.9824561403508771, Recall=0.9974554707379135, F1-score=0.98989898989899\n",
            "Decision Tree: Accuracy=0.9829842931937173, Precision=0.9846938775510204, Recall=0.9821882951653944, F1-score=0.9834394904458599\n",
            "Naive Bayes: Accuracy=0.9502617801047121, Precision=0.9382716049382716, Recall=0.9669211195928753, F1-score=0.9523809523809523\n"
          ]
        }
      ],
      "source": [
        "# Evaluate SVM model\n",
        "svm_accuracy = accuracy_score(val_labels_numpy, y_pred)\n",
        "svm_precision = precision_score(val_labels_numpy, y_pred)\n",
        "svm_recall = recall_score(val_labels_numpy, y_pred)\n",
        "svm_f1 = f1_score(val_labels_numpy, y_pred)\n",
        "\n",
        "# Evaluate KNN model\n",
        "knn_accuracy = accuracy_score(val_labels_numpy, y_pred_knn)\n",
        "knn_precision = precision_score(val_labels_numpy, y_pred_knn)\n",
        "knn_recall = recall_score(val_labels_numpy, y_pred_knn)\n",
        "knn_f1 = f1_score(val_labels_numpy, y_pred_knn)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "rf_accuracy = accuracy_score(val_labels_numpy, rf_predictions)\n",
        "rf_precision = precision_score(val_labels_numpy, rf_predictions)\n",
        "rf_recall = recall_score(val_labels_numpy, rf_predictions)\n",
        "rf_f1 = f1_score(val_labels_numpy, rf_predictions)\n",
        "\n",
        "# Evaluate Decision Tree model\n",
        "dt_accuracy = accuracy_score(val_labels_numpy, dt_predictions)\n",
        "dt_precision = precision_score(val_labels_numpy, dt_predictions)\n",
        "dt_recall = recall_score(val_labels_numpy, dt_predictions)\n",
        "dt_f1 = f1_score(val_labels_numpy, dt_predictions)\n",
        "\n",
        "# Evaluate Naive Bayes model\n",
        "nb_accuracy = accuracy_score(val_labels_numpy, nb_predictions)\n",
        "nb_precision = precision_score(val_labels_numpy, nb_predictions)\n",
        "nb_recall = recall_score(val_labels_numpy, nb_predictions)\n",
        "nb_f1 = f1_score(val_labels_numpy, nb_predictions)\n",
        "\n",
        "\n",
        "# Print performance metrics\n",
        "print(\"Performance Metrics:\")\n",
        "print(f\"SVM: Accuracy={svm_accuracy}, Precision={svm_precision}, Recall={svm_recall}, F1-score={svm_f1}\")\n",
        "print(f\"KNN: Accuracy={knn_accuracy}, Precision={knn_precision}, Recall={knn_recall}, F1-score={knn_f1}\")\n",
        "print(f\"Random Forest: Accuracy={rf_accuracy}, Precision={rf_precision}, Recall={rf_recall}, F1-score={rf_f1}\")\n",
        "print(f\"Decision Tree: Accuracy={dt_accuracy}, Precision={dt_precision}, Recall={dt_recall}, F1-score={dt_f1}\")\n",
        "print(f\"Naive Bayes: Accuracy={nb_accuracy}, Precision={nb_precision}, Recall={nb_recall}, F1-score={nb_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have your data ready, val_loader, val_labels\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "# Assuming your model is already defined and trained\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred, y_true = evaluate_model(model, val_loader)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Print performance metrics\n",
        "print(\"Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.16f}\")\n",
        "print(f\"Precision: {precision:.16f}\")\n",
        "print(f\"Recall: {recall:.16f}\")\n",
        "print(f\"F1-score: {f1:.16f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcDIA0SNtPTB",
        "outputId": "52646930-e7e3-4a05-b6be-60aba97cc1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Metrics:\n",
            "Accuracy: 1.0000000000000000\n",
            "Precision: 1.0000000000000000\n",
            "Recall: 1.0000000000000000\n",
            "F1-score: 1.0000000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print performance metrics\n",
        "print(\"Performance Metrics:\")\n",
        "print(f\"SVM: Accuracy={svm_accuracy}, Precision={svm_precision}, Recall={svm_recall}, F1-score={svm_f1}\")\n",
        "print(f\"KNN: Accuracy={knn_accuracy}, Precision={knn_precision}, Recall={knn_recall}, F1-score={knn_f1}\")\n",
        "print(f\"Random Forest: Accuracy={rf_accuracy}, Precision={rf_precision}, Recall={rf_recall}, F1-score={rf_f1}\")\n",
        "print(f\"Decision Tree: Accuracy={dt_accuracy}, Precision={dt_precision}, Recall={dt_recall}, F1-score={dt_f1}\")\n",
        "print(f\"Naive Bayes: Accuracy={nb_accuracy}, Precision={nb_precision}, Recall={nb_recall}, F1-score={nb_f1}\")\n",
        "print(f\"CNN: Accuracy= {accuracy:.16f}, Precision= {precision:.16f} , Recall={recall:.16f} , F1-score={f1:.16f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyKP3nvjt8dr",
        "outputId": "5703239e-1833-4a0d-ebe1-8c1a186a0230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Metrics:\n",
            "SVM: Accuracy=0.9973821989528796, Precision=0.9974554707379135, Recall=0.9974554707379135, F1-score=0.9974554707379135\n",
            "KNN: Accuracy=0.9790575916230366, Precision=0.960880195599022, Recall=1.0, F1-score=0.9800498753117207\n",
            "Random Forest: Accuracy=0.9895287958115183, Precision=0.9824561403508771, Recall=0.9974554707379135, F1-score=0.98989898989899\n",
            "Decision Tree: Accuracy=0.9829842931937173, Precision=0.9846938775510204, Recall=0.9821882951653944, F1-score=0.9834394904458599\n",
            "Naive Bayes: Accuracy=0.9502617801047121, Precision=0.9382716049382716, Recall=0.9669211195928753, F1-score=0.9523809523809523\n",
            "CNN: Accuracy= 1.0000000000000000, Precision= 1.0000000000000000 , Recall=1.0000000000000000 , F1-score=1.0000000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mo6ZovDXuvye"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}